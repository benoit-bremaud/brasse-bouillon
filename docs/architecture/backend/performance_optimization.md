# âš¡ **Optimisation des Performances Backend - Brasse-Bouillon**  

## ğŸ“Œ **Introduction**  

Lâ€™optimisation des performances du backend **est essentielle** pour garantir :  
âœ… **Une API rapide et rÃ©active**, mÃªme avec de nombreuses requÃªtes simultanÃ©es.  
âœ… **Une base de donnÃ©es bien optimisÃ©e**, Ã©vitant les ralentissements.  
âœ… **Un systÃ¨me scalable**, capable de gÃ©rer une montÃ©e en charge.  

ğŸ“Œ **StratÃ©gies dâ€™optimisation couvertes dans ce document :**  
1ï¸âƒ£ **Caching pour rÃ©duire les requÃªtes inutiles**.  
2ï¸âƒ£ **Optimisation des requÃªtes SQL et pagination**.  
3ï¸âƒ£ **Gestion de la charge avec Load Balancing**.  
4ï¸âƒ£ **Optimisation des logs et monitoring des performances**.  
5ï¸âƒ£ **SÃ©curisation et limitation des requÃªtes (Rate Limiting, Compression)**.  

ğŸ“Œ **Technologies utilisÃ©es :**  

- **Redis** pour le caching.  
- **Sequelize ORM** pour optimiser les requÃªtes SQL.  
- **NGINX / Load Balancing** pour rÃ©partir la charge.  
- **Express Rate Limit** pour Ã©viter les abus API.  
- **PM2 / Cluster Mode** pour exÃ©cuter plusieurs instances du serveur.  

---

## ğŸ“Š **SchÃ©ma Global des Optimisations Backend**

ğŸ“Œ **Vue simplifiÃ©e des optimisations appliquÃ©es.**  

```mermaid
graph TD;
    API["ğŸŒ API Backend (Node.js + Express)"]
    Cache["âš¡ Caching (Redis)"]
    DB["ğŸ—„ï¸ Base de DonnÃ©es (PostgreSQL)"]
    LoadBalancer["ğŸ”€ Load Balancer (NGINX)"]
    Logger["ğŸ“Š Monitoring & Logs (PM2, Winston)"]
    RateLimiter["ğŸ“‰ Rate Limiting & SÃ©curitÃ©"]
    
    API -->|Stocke et rÃ©cupÃ¨re| Cache
    API -->|Interroge efficacement| DB
    API -->|RÃ©parti la charge| LoadBalancer
    API -->|Analyse et optimise| Logger
    API -->|ProtÃ¨ge contre les abus| RateLimiter
```

---

## **ğŸ› ï¸ 1ï¸âƒ£ Mise en Place dâ€™un Caching (Redis)**

ğŸ“Œ **Objectif :** **RÃ©duire le nombre de requÃªtes rÃ©pÃ©titives** vers la base de donnÃ©es en mettant en cache les rÃ©ponses API.  

ğŸ“Œ **Exemple de mise en cache avec Redis :**  

```javascript
const redis = require("redis");
const client = redis.createClient();

const cacheMiddleware = (req, res, next) => {
    const key = req.originalUrl;
    client.get(key, (err, data) => {
        if (data) {
            return res.json(JSON.parse(data));
        }
        next();
    });
};

app.get("/recipes", cacheMiddleware, async (req, res) => {
    const recipes = await Recipe.findAll();
    client.setex(req.originalUrl, 3600, JSON.stringify(recipes)); // Cache pour 1h
    res.json(recipes);
});
```

âœ… **Avantages du caching Redis :**  
âœ” **Diminution du temps de rÃ©ponse** (Ã©vite les requÃªtes rÃ©pÃ©tÃ©es en base).  
âœ” **DÃ©chargement de la base de donnÃ©es** (moins de lecture).  

---

## **ğŸ” 2ï¸âƒ£ Optimisation des RequÃªtes SQL**

ğŸ“Œ **Objectif :** RÃ©duire **les requÃªtes lourdes** et amÃ©liorer **les performances SQL**.  

ğŸ“Œ **Indexation des colonnes frÃ©quemment interrogÃ©es :**  

```sql
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_recipes_name ON recipes(name);
```

ğŸ“Œ **Pagination efficace pour Ã©viter le chargement de grandes quantitÃ©s de donnÃ©es :**  

```javascript
app.get("/recipes", async (req, res) => {
    const { page = 1, limit = 10 } = req.query;
    const offset = (page - 1) * limit;
    
    const recipes = await Recipe.findAndCountAll({
        limit: parseInt(limit),
        offset: parseInt(offset)
    });

    res.json({
        total: recipes.count,
        page: page,
        totalPages: Math.ceil(recipes.count / limit),
        data: recipes.rows
    });
});
```

âœ… **Pourquoi câ€™est important ?**  
âœ” **Ã‰vite les requÃªtes SQL volumineuses**.  
âœ” **Charge les donnÃ©es progressivement** plutÃ´t que tout en une seule fois.  

---

## **ğŸ”€ 3ï¸âƒ£ Load Balancing & ScalabilitÃ©**

ğŸ“Œ **Objectif :** **GÃ©rer un grand nombre de requÃªtes** sans surcharge dâ€™un seul serveur.  

ğŸ“Œ **Exemple de configuration `NGINX` pour Load Balancing :**  

```nginx
upstream backend_servers {
    server backend1:3000;
    server backend2:3000;
}

server {
    listen 80;
    location / {
        proxy_pass http://backend_servers;
    }
}
```

âœ… **Avantages :**  
âœ” **RÃ©partit la charge entre plusieurs instances**.  
âœ” **AmÃ©liore la haute disponibilitÃ©** du backend.  

---

## **ğŸ“Š 4ï¸âƒ£ Monitoring et Optimisation des Logs**

ğŸ“Œ **Objectif :** Suivre les performances et dÃ©tecter les problÃ¨mes en temps rÃ©el.  

ğŸ“Œ **Utilisation de PM2 pour gÃ©rer les processus Node.js**  

```bash
pm2 start server.js -i max  # DÃ©marre plusieurs instances
pm2 monit  # Affiche les logs en temps rÃ©el
```

ğŸ“Œ **Utilisation de Winston pour logger les erreurs et les performances**  

```javascript
const winston = require("winston");

const logger = winston.createLogger({
    level: "info",
    transports: [
        new winston.transports.Console(),
        new winston.transports.File({ filename: "logs/error.log", level: "error" })
    ]
});

logger.info("API dÃ©marrÃ©e avec succÃ¨s !");
logger.error("Erreur critique dÃ©tectÃ©e !");
```

âœ… **Pourquoi utiliser du monitoring ?**  
âœ” **DÃ©tecter les erreurs en temps rÃ©el**.  
âœ” **Analyser les performances et optimiser les requÃªtes lentes**.  

---

## **ğŸ“‰ 5ï¸âƒ£ SÃ©curisation et Limitation des RequÃªtes**

ğŸ“Œ **Objectif :** **EmpÃªcher les attaques par dÃ©ni de service (DoS) et les abus dâ€™API.**  

ğŸ“Œ **Utilisation de `express-rate-limit` pour limiter le nombre de requÃªtes :**  

```javascript
const rateLimit = require("express-rate-limit");

const limiter = rateLimit({
    windowMs: 15 * 60 * 1000, // 15 minutes
    max: 100, // 100 requÃªtes max par IP
    message: "Trop de requÃªtes, veuillez rÃ©essayer plus tard."
});

app.use("/auth/login", limiter);
```

ğŸ“Œ **Compression des rÃ©ponses API pour rÃ©duire la bande passante**  

```javascript
const compression = require("compression");
app.use(compression());
```

âœ… **Pourquoi ces mesures sont importantes ?**  
âœ” **EmpÃªche les attaques par force brute** sur lâ€™authentification.  
âœ” **AmÃ©liore les performances en rÃ©duisant la taille des rÃ©ponses**.  
